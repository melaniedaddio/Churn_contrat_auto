{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e22e5da",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0bbb0",
   "metadata": {},
   "source": [
    "## 1.1 Préparation à la modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1ca71",
   "metadata": {},
   "source": [
    "### 1.1.1 Séparation Apprentissage/test/validation (70% / 15% / 15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca79a03",
   "metadata": {},
   "source": [
    "⚠️ faire attention au desiquilibre de la variable cible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50075e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc554fdc",
   "metadata": {},
   "source": [
    "⚠️ ATTENTION pour la normalisation, valeurs manquantes et encodage (target encoding) : \n",
    "- Sur train : on fit + transform. => Parce que c’est l'entraînement qui découvre la structure des données (on entraîne le modèle dessus)\n",
    "- Sur test (ou validation) : on transform uniquement, jamais fit. => Parce que c’est l'entraînement qui découvre la structure des données (on entraîne le modèle dessus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea569f56",
   "metadata": {},
   "source": [
    "### 1.1.2 Normalisation des variables continues "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489653b7",
   "metadata": {},
   "source": [
    "La normalisation des variables continues est utile seulement dans le cas du modèle de regression logistique (surtout si l'ont fait une regularisation par la suite -> ce qui est notre cas). Pour les modèles à base d'arbre ce n'est pas utile car c'est basé sur une méthode de découpe et non de distance.\n",
    "\n",
    "Ici il est necessaire que nous la fassions car nous allons effectuer un traitement des valeur manquantes des variables continues à l'aide des KNN et il est necessaire que nos variables soient normalisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859078fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standar scaler \n",
    "# attention faire fit sur train et transform sur train et test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465f9c3",
   "metadata": {},
   "source": [
    "### 1.1.3 Traitement des valeurs manquantes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d02d9d",
   "metadata": {},
   "source": [
    "Pour les variables continues il est souvent judicieux de faire les KNN (attention normaliser les données avant de faire un KNN). Pour les variables catégorielles remplacer par une modalité \"unknow\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb326b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention : faire fit sur train et transform sur train et test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976e1c7",
   "metadata": {},
   "source": [
    "### 1.1.4 Encodage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b80b0",
   "metadata": {},
   "source": [
    "Bien regarder apres analyse si on peut reunir certaines modalités ensembles. Puis : \n",
    "- Pour les variables à moins de 5 modalité faire label encoding ou order encoding (s'il y a un ordre)\n",
    "- Pour les variables à plus de 5 modalité faire CatBoost encoder (TargetEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention : faire fit sur train et transform sur train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fc4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "454dd7eb",
   "metadata": {},
   "source": [
    "# 2. Modèle à base d'arbres "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3487a",
   "metadata": {},
   "source": [
    "⚠️ Soit on fait qu'un random forest qui est suffisant. Soit on fait comme dans le notebook du prof et on compare \"Random Forest\", \"Gradient Boosting\", \"LightGBM\".\n",
    "\n",
    "Si on fait un modele de type gradient boosting pas besoin de traiter les valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c613377",
   "metadata": {},
   "source": [
    "## 2.1 Modelisation simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3082d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aab7cbe",
   "metadata": {},
   "source": [
    "## 2.2 Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b2b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef764466",
   "metadata": {},
   "source": [
    "## 2.3 Déterminer un seuil (approche métier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c8357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
