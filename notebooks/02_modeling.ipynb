{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9374a60c",
   "metadata": {},
   "source": [
    "# ğŸ“Œ RÃ©sumÃ©\n",
    "\n",
    "## ğŸ” ModÃ¨les utilisÃ©s\n",
    "\n",
    "1. **RÃ©gression logistique**  \n",
    "   ModÃ¨le de base simple et rapide Ã  entraÃ®ner. TrÃ¨s utile comme point de comparaison.  \n",
    "   - âœ… InterprÃ©table : les coefficients indiquent lâ€™influence de chaque variable. (utile dans un contexte metier)\n",
    "   - âœ… Performant sur des donnÃ©es linÃ©airement sÃ©parables.\n",
    "   - âŒ Peut Ãªtre limitÃ© si les relations entre variables sont non linÃ©aires.\n",
    "\n",
    "2. **Arbre de dÃ©cision**  \n",
    "   MÃ©thode intuitive qui segmente lâ€™espace de dÃ©cision via des rÃ¨gles simples.  \n",
    "   - âœ… Facilement lisible et interprÃ©table.\n",
    "   - âœ… CapacitÃ© Ã  identifier les variables les plus importantes.\n",
    "   - âŒ Risque de surapprentissage sâ€™il nâ€™est pas bien rÃ©gularisÃ©.\n",
    "\n",
    "3. **Random Forest**  \n",
    "   Ensemble dâ€™arbres de dÃ©cision crÃ©Ã©s Ã  partir de sous-Ã©chantillons alÃ©atoires des donnÃ©es.  \n",
    "   - âœ… RÃ©duit le surapprentissage grÃ¢ce Ã  lâ€™agrÃ©gation (bagging).\n",
    "   - âœ… GÃ©nÃ©ralement plus robuste et performant quâ€™un arbre unique.\n",
    "   - âœ… Moins coÃ»teux en calcul et plus facile Ã  paramÃ©trer quâ€™un modÃ¨le comme XGBoost.\n",
    "   - âŒ Moins interprÃ©table quâ€™un arbre simple, mais on peut extraire lâ€™importance des variables.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Objectif d'optimisation : le **F1-score**\n",
    "\n",
    "L'objectif est de prÃ©dire quels clients vont **rÃ©silier**.\n",
    "Nous avons choisi d'optimiser le **F1-Score**\n",
    "\n",
    "- **PrÃ©cision** = parmi les clients que le modÃ¨le prÃ©dit comme \"Ã  risque\", combien le sont rÃ©ellement ?\n",
    "- **Rappel** = parmi les clients qui vont rÃ©ellement rÃ©silier, combien le modÃ¨le arrive-t-il Ã  dÃ©tecter ?\n",
    "\n",
    "Optimiser uniquement la prÃ©cision :\n",
    "- â• Moins de faux positifs.\n",
    "- â– Mais risque de rater beaucoup de vrais rÃ©siliants.\n",
    "\n",
    "Optimiser uniquement le rappel :\n",
    "- â• On identifie la majoritÃ© des vrais rÃ©siliants.\n",
    "- â– Mais on cible aussi beaucoup de clients Ã  tort (faux positifs), ce qui coÃ»te cher.\n",
    "\n",
    "ğŸ‘‰ **F1-score = compromis entre prÃ©cision et rappel**  \n",
    "Câ€™est une mÃ©trique Ã©quilibrÃ©e, idÃ©ale dans notre cas oÃ¹ :\n",
    "- Les classes sont dÃ©sÃ©quilibrÃ©es ainsi l'accuracy n'est pas rÃ©ellement interpretable.\n",
    "- Les **faux nÃ©gatifs** (clients Ã  risque non dÃ©tectÃ©s) et les **faux positifs** (clients mal classÃ©s) ont **tous deux un impact business important**.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Optimisation des hyperparamÃ¨tres\n",
    "\n",
    "Pour amÃ©liorer les performances des modÃ¨les, plusieurs mÃ©thodes ont Ã©tÃ© utilisÃ©es :\n",
    "\n",
    "1. **Recherche par grille (Grid Search)**  \n",
    "   - Explore toutes les combinaisons possibles de paramÃ¨tres dans un espace dÃ©fini.\n",
    "\n",
    "2. **Recherche alÃ©atoire (Random Search)**  \n",
    "   - Tire au hasard des combinaisons dans lâ€™espace des paramÃ¨tres. Plus rapide que Grid Search dans de nombreux cas.\n",
    "\n",
    "3. **Optimisation bayÃ©sienne**  \n",
    "   - Utilise les rÃ©sultats prÃ©cÃ©dents pour choisir plus intelligemment les combinaisons suivantes.\n",
    "   - Plus efficace et Ã©conome en calcul, surtout avec des modÃ¨les coÃ»teux Ã  entraÃ®ner.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
