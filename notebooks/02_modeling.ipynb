{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9374a60c",
   "metadata": {},
   "source": [
    "# 📌 Résumé\n",
    "\n",
    "## 🔍 Modèles utilisés\n",
    "\n",
    "1. **Régression logistique**  \n",
    "   Modèle de base simple et rapide à entraîner. Très utile comme point de comparaison.  \n",
    "   - ✅ Interprétable : les coefficients indiquent l’influence de chaque variable. (utile dans un contexte metier)\n",
    "   - ✅ Performant sur des données linéairement séparables.\n",
    "   - ❌ Peut être limité si les relations entre variables sont non linéaires.\n",
    "\n",
    "2. **Arbre de décision**  \n",
    "   Méthode intuitive qui segmente l’espace de décision via des règles simples.  \n",
    "   - ✅ Facilement lisible et interprétable.\n",
    "   - ✅ Capacité à identifier les variables les plus importantes.\n",
    "   - ❌ Risque de surapprentissage s’il n’est pas bien régularisé.\n",
    "\n",
    "3. **Random Forest**  \n",
    "   Ensemble d’arbres de décision créés à partir de sous-échantillons aléatoires des données.  \n",
    "   - ✅ Réduit le surapprentissage grâce à l’agrégation (bagging).\n",
    "   - ✅ Généralement plus robuste et performant qu’un arbre unique.\n",
    "   - ✅ Moins coûteux en calcul et plus facile à paramétrer qu’un modèle comme XGBoost.\n",
    "   - ❌ Moins interprétable qu’un arbre simple, mais on peut extraire l’importance des variables.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Objectif d'optimisation : le **F1-score**\n",
    "\n",
    "L'objectif est de prédire quels clients vont **résilier**.\n",
    "Nous avons choisi d'optimiser le **F1-Score**\n",
    "\n",
    "- **Précision** = parmi les clients que le modèle prédit comme \"à risque\", combien le sont réellement ?\n",
    "- **Rappel** = parmi les clients qui vont réellement résilier, combien le modèle arrive-t-il à détecter ?\n",
    "\n",
    "Optimiser uniquement la précision :\n",
    "- ➕ Moins de faux positifs.\n",
    "- ➖ Mais risque de rater beaucoup de vrais résiliants.\n",
    "\n",
    "Optimiser uniquement le rappel :\n",
    "- ➕ On identifie la majorité des vrais résiliants.\n",
    "- ➖ Mais on cible aussi beaucoup de clients à tort (faux positifs), ce qui coûte cher.\n",
    "\n",
    "👉 **F1-score = compromis entre précision et rappel**  \n",
    "C’est une métrique équilibrée, idéale dans notre cas où :\n",
    "- Les classes sont déséquilibrées ainsi l'accuracy n'est pas réellement interpretable.\n",
    "- Les **faux négatifs** (clients à risque non détectés) et les **faux positifs** (clients mal classés) ont **tous deux un impact business important**.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Optimisation des hyperparamètres\n",
    "\n",
    "Pour améliorer les performances des modèles, plusieurs méthodes ont été utilisées :\n",
    "\n",
    "1. **Recherche par grille (Grid Search)**  \n",
    "   - Explore toutes les combinaisons possibles de paramètres dans un espace défini.\n",
    "\n",
    "2. **Recherche aléatoire (Random Search)**  \n",
    "   - Tire au hasard des combinaisons dans l’espace des paramètres. Plus rapide que Grid Search dans de nombreux cas.\n",
    "\n",
    "3. **Optimisation bayésienne**  \n",
    "   - Utilise les résultats précédents pour choisir plus intelligemment les combinaisons suivantes.\n",
    "   - Plus efficace et économe en calcul, surtout avec des modèles coûteux à entraîner.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
