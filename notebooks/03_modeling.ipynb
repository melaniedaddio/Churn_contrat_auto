{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9374a60c",
   "metadata": {},
   "source": [
    "# üìå R√©sum√©\n",
    "\n",
    "## üîç Mod√®les utilis√©s\n",
    "\n",
    "1. **R√©gression logistique**  \n",
    "   Mod√®le de base simple et rapide √† entra√Æner. Tr√®s utile comme point de comparaison.  \n",
    "   - ‚úÖ Interpr√©table : les coefficients indiquent l‚Äôinfluence de chaque variable. (utile dans un contexte metier)\n",
    "   - ‚úÖ Performant sur des donn√©es lin√©airement s√©parables.\n",
    "   - ‚ùå Peut √™tre limit√© si les relations entre variables sont non lin√©aires.\n",
    "\n",
    "2. **Arbre de d√©cision**  \n",
    "   M√©thode intuitive qui segmente l‚Äôespace de d√©cision via des r√®gles simples.  \n",
    "   - ‚úÖ Facilement lisible et interpr√©table.\n",
    "   - ‚úÖ Capacit√© √† identifier les variables les plus importantes.\n",
    "   - ‚ùå Risque de surapprentissage s‚Äôil n‚Äôest pas bien r√©gularis√©.\n",
    "\n",
    "3. **Random Forest**  \n",
    "   Ensemble d‚Äôarbres de d√©cision cr√©√©s √† partir de sous-√©chantillons al√©atoires des donn√©es.  \n",
    "   - ‚úÖ R√©duit le surapprentissage gr√¢ce √† l‚Äôagr√©gation (bagging).\n",
    "   - ‚úÖ G√©n√©ralement plus robuste et performant qu‚Äôun arbre unique.\n",
    "   - ‚úÖ Moins co√ªteux en calcul et plus facile √† param√©trer qu‚Äôun mod√®le comme XGBoost.\n",
    "   - ‚ùå Moins interpr√©table qu‚Äôun arbre simple, mais on peut extraire l‚Äôimportance des variables.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectif d'optimisation : le **F1-score**\n",
    "\n",
    "L'objectif est de pr√©dire quels clients vont **r√©silier**.\n",
    "Nous avons choisi d'optimiser le **F1-Score**\n",
    "\n",
    "- **Pr√©cision** = parmi les clients que le mod√®le pr√©dit comme \"√† risque\", combien le sont r√©ellement ?\n",
    "- **Rappel** = parmi les clients qui vont r√©ellement r√©silier, combien le mod√®le arrive-t-il √† d√©tecter ?\n",
    "\n",
    "Optimiser uniquement la pr√©cision :\n",
    "- ‚ûï Moins de faux positifs.\n",
    "- ‚ûñ Mais risque de rater beaucoup de vrais r√©siliants.\n",
    "\n",
    "Optimiser uniquement le rappel :\n",
    "- ‚ûï On identifie la majorit√© des vrais r√©siliants.\n",
    "- ‚ûñ Mais on cible aussi beaucoup de clients √† tort (faux positifs), ce qui co√ªte cher.\n",
    "\n",
    "üëâ **F1-score = compromis entre pr√©cision et rappel**  \n",
    "C‚Äôest une m√©trique √©quilibr√©e, id√©ale dans notre cas o√π :\n",
    "- Les classes sont d√©s√©quilibr√©es ainsi l'accuracy n'est pas r√©ellement interpretable.\n",
    "- Les **faux n√©gatifs** (clients √† risque non d√©tect√©s) et les **faux positifs** (clients mal class√©s) ont **tous deux un impact business important**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Optimisation des hyperparam√®tres\n",
    "\n",
    "Pour am√©liorer les performances des mod√®les, plusieurs m√©thodes ont √©t√© utilis√©es :\n",
    "\n",
    "1. **Recherche par grille (Grid Search)**  \n",
    "   - Explore toutes les combinaisons possibles de param√®tres dans un espace d√©fini.\n",
    "\n",
    "2. **Recherche al√©atoire (Random Search)**  \n",
    "   - Tire au hasard des combinaisons dans l‚Äôespace des param√®tres. Plus rapide que Grid Search dans de nombreux cas.\n",
    "\n",
    "3. **Optimisation bay√©sienne**  \n",
    "   - Utilise les r√©sultats pr√©c√©dents pour choisir plus intelligemment les combinaisons suivantes.\n",
    "   - Plus efficace et √©conome en calcul, surtout avec des mod√®les co√ªteux √† entra√Æner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f56f99",
   "metadata": {},
   "source": [
    "# 1. R√©gression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1922d",
   "metadata": {},
   "source": [
    "## 1.1 Selection de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd92bb",
   "metadata": {},
   "source": [
    "Ce type de mod√®le contraireemnt aux mod√®les \"d'arbres\" n√©cessitent une selection de variables. Pour ce faire nous allons dans un prmeier temps se baser sur les variables qui nous ont paru pertinentes au cour de notre data exploration. Puis nous comparerons les selection de variables avec Lasso, Ridge et Elastic Net."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2dddc",
   "metadata": {},
   "source": [
    "### 1.1.1 S√©lection de variables √† l'aide de : l'analyse exploratoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e7dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec29dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5cd5f09",
   "metadata": {},
   "source": [
    "### 1.1.2 Selection de variables √† l'aide de Lasso, Ridge et Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5806455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a918820",
   "metadata": {},
   "source": [
    "## 1.2 Modelisation simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91086159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becfa147",
   "metadata": {},
   "source": [
    "## 1.3 Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218f53a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f515da",
   "metadata": {},
   "source": [
    "## 1.4 D√©terminer un seuil (approche m√©tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa055177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4247b2f6",
   "metadata": {},
   "source": [
    "# 2. Arbre de d√©cision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c18c1e",
   "metadata": {},
   "source": [
    "## 2.1 Modelisation simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd8f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94ffbdbb",
   "metadata": {},
   "source": [
    "## 2.2 Optimisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4af961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82e5d346",
   "metadata": {},
   "source": [
    "## 2.3 D√©terminer un seuil (approche m√©tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf9590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f882a77",
   "metadata": {},
   "source": [
    "# 3. Mod√®le √† base d'arbres "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266b5ca",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Soit on fait qu'un random forest qui est suffisant. Soit on fait comme dans le notebook du prof et on compare \"Random Forest\", \"Gradient Boosting\", \"LightGBM\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5afe5f",
   "metadata": {},
   "source": [
    "## 3.1 Modelisation simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c163ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8662314e",
   "metadata": {},
   "source": [
    "## 3.2 Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973d5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a54dece6",
   "metadata": {},
   "source": [
    "## 3.3 D√©terminer un seuil (approche m√©tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1d33a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
